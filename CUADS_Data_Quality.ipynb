{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# CUADS Data Quality Notebook\n",
    "\n",
    "## About CUADS\n",
    "CUADS is a multimodal dataset contained ECG, PPG and GSR physiological signals recorded while participants viewed pre-tagged affective movie clips. After each movie clip, participants completed a SAM survey to evaluate arousal and valence.\n",
    "\n",
    "The dataset can obtained from IEEE DataPort here: [https://ieee-dataport.org/documents/clarkson-university-affective-dataset-cuads](https://ieee-dataport.org/documents/clarkson-university-affective-dataset-cuads)\n",
    "\n",
    "\n",
    "## About this notebook\n",
    "This notebook is used to perform quality assessment of the data contained in CUADS. We evaluate and score each of the three physiological signals, and the SAM survey response data.\n",
    "\n",
    "## Instructions\n",
    "Download and extract the CUADS dataset. In the first cell, update the value `dataset_root` to path to the `cuads` folder in the extracted dataset. This notebook produces several output images. The path to save the output can be set in the `dataset_output` variable, and defaults to `./output`.\n",
    "\n",
    "For help, please reach out to the authors."
   ]
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-26T14:49:11.573822Z",
     "start_time": "2025-01-26T14:49:11.449720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa, aggregate_raters\n",
    "\n",
    "# Path to the extracted dataset\n",
    "dataset_root='./dataset/cuads'\n",
    "\n",
    "# Path to write output images and numpy files\n",
    "dataset_output=f'./output'\n",
    "\n",
    "if not os.path.exists(dataset_root):\n",
    "    print(\"ERROR: No dataset found at {dataset_root}\")\n",
    "\n",
    "if not os.path.exists(dataset_output):\n",
    "    os.mkdir(dataset_output)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:49:11.577133Z",
     "start_time": "2025-01-26T14:49:11.575844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Fs=256                      # Physiological signal sampling rate. DO NOT MODIFY.\n",
    "CUADS_NUM_PARTICIPANTS=44   # CUADS enrolled 44 participants.\n",
    "CUADS_NUM_MOVIECLIPS=20     # Participants were each shown 20 movie clips"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ECG Scoring\n",
    "\n",
    "The following cell scores the ECGs using NeuroKit2. NeuroKit2 ontains several methods for cleaning an ECG, listed in the `methods` list. The Zhoe2018 method scores the cleaned ECG, rating them as `unacceptable`, `barely acceptable` or `excellent`\n",
    "\n",
    "For each ecg signal in the dataset, we attempt to find the NeuroKit2 method that results in the highest quality score.\n",
    "\n",
    "__NOTE:__ in the Descriptor: Clarkson University Affective Dataset (CUADS) paper, we only report quality results using the Neurokit2 Method. Neurokit2\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:51:58.863592Z",
     "start_time": "2025-01-26T14:49:11.620403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Map column numbers to ECG Channel Names - only used for logging\n",
    "column_to_channel_name = {15: \"LA-RA\", 16: \"LL-LA\", 17: \"LL-RA\"}\n",
    "\n",
    "# Map Zhao2018 result labels to integer values\n",
    "quality_map = { \"Unacceptable\": 0, \"Barely acceptable\": 1, \"Excellent\": 2 }\n",
    "\n",
    "# List of methods for ECG Cleaning in NeuroKit2\n",
    "methods = [\"neurokit\", \"biosppy\", \"pantompkins1985\", \"hamilton2002\", \"elgendi2010\", \"engzeemod2012\", \"vg\"]\n",
    "\n",
    "# Used to track how many times each method resulted in the best score for each signal\n",
    "bestmethod_counts = {\"neurokit\": 0, \"biosppy\": 0, \"pantompkins1985\": 0, \"hamilton2002\": 0, \"elgendi2010\": 0, \"engzeemod2012\": 0, \"vg\": 0}\n",
    "\n",
    "# Used to track how many ecg signals received each score\n",
    "quality_results = { 0: 0, 1: 0, 2: 0 }\n",
    "\n",
    "# Used to track the best scores by ecg-channel\n",
    "quality_by_channel = {0: { 0: 0, 1: 0, 2: 0 }, 1: { 0: 0, 1: 0, 2: 0 }, 2: { 0: 0, 1: 0, 2: 0 } }\n",
    "\n",
    "for p in range(CUADS_NUM_PARTICIPANTS):\n",
    "    folder = f\"{dataset_root}/CUADS_{(p+1):03}\"\n",
    "    if not os.path.exists(folder):\n",
    "        continue\n",
    "\n",
    "    # Load this participant's responses...\n",
    "    responses = np.loadtxt(f\"{folder}/responses.csv\", delimiter=',', dtype=str, skiprows=1)\n",
    "\n",
    "    for c, response in enumerate(responses):\n",
    "        movie_name = response[0]\n",
    "        segmented_data_filepath = f'{folder}/segmented/{movie_name}_sessiondata.csv'\n",
    "        if not os.path.exists(segmented_data_filepath):\n",
    "            #print(f\"No segmented datafile found: {segmented_data_filepath}\")\n",
    "            continue\n",
    "\n",
    "        segmented_data = np.loadtxt(segmented_data_filepath, delimiter=',', dtype=str, skiprows=1)\n",
    "\n",
    "        ## ECG LA-RA 24-Bit = Column 16\n",
    "        ## ECG LL-LA 24-Bit = Column 17\n",
    "        ## ECG LL-RA 24-Bit = Column 18\n",
    "        for channel in np.arange(15,18):\n",
    "            quality = \"x\"\n",
    "            channel_dat=segmented_data[:,channel]\n",
    "            channel_dat = np.array(channel_dat, dtype=np.float64)\n",
    "\n",
    "            methodidx = 0\n",
    "            best_quality = -1\n",
    "            best_quality_method = \"\"\n",
    "\n",
    "            # Loop until we get an \"Excellent\" result, or run out of methods to test...\n",
    "            while quality != \"Excellent\" and methodidx < len(methods):\n",
    "                current_method = methods[methodidx]\n",
    "\n",
    "                # Clean the ECG signal using the current method\n",
    "                ecg_cleaned = nk.ecg_clean(channel_dat, sampling_rate=Fs, powerline=60, method=current_method)\n",
    "\n",
    "                # Evaluate the ECG signal using fuzzy comprehensive SQI evaluation\n",
    "                quality = nk.ecg_quality(ecg_cleaned, sampling_rate=Fs, method='zhao2018', approach=\"fuzzy\")\n",
    "\n",
    "                # Is this better than the best one we've found so far?\n",
    "                if quality_map[quality] > best_quality:\n",
    "                    best_quality = quality_map[quality]\n",
    "                    best_quality_method = current_method\n",
    "\n",
    "                methodidx += 1\n",
    "\n",
    "            quality_by_channel[channel-15][best_quality] += 1\n",
    "            bestmethod_counts[best_quality_method] += 1\n",
    "            quality_results[best_quality] += 1\n",
    "\n",
    "            #print(f\"Participant {p+1} Video {c} Channel {column_to_channel_name[channel]}: Best Method {best_quality_method}, Best Quality: {best_quality}\")\n",
    "\n",
    "print(\"\\nECG Signal Counts by Best Quality (0=Unacceptable, 1=Barely acceptable, 2=Excellent)\")\n",
    "print(quality_results)\n",
    "\n",
    "print(\"\\nECG Signal Counts by Best Method\")\n",
    "print(bestmethod_counts)\n",
    "\n",
    "print(\"\\nECG Signal Counts by By ECG-Channel (0=LA-RA, 1=LL-LA, 2=LL-RA)\")\n",
    "print(quality_by_channel)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ECG Signal Counts by Best Quality (0=Unacceptable, 1=Barely acceptable, 2=Excellent)\n",
      "{0: 0, 1: 0, 2: 2142}\n",
      "\n",
      "ECG Signal Counts by Best Method\n",
      "{'neurokit': 1824, 'biosppy': 100, 'pantompkins1985': 156, 'hamilton2002': 62, 'elgendi2010': 0, 'engzeemod2012': 0, 'vg': 0}\n",
      "\n",
      "ECG Signal Counts by By ECG-Channel (0=LA-RA, 1=LL-LA, 2=LL-RA)\n",
      "{0: {0: 0, 1: 0, 2: 714}, 1: {0: 0, 1: 0, 2: 714}, 2: {0: 0, 1: 0, 2: 714}}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# PPG Scoring\n",
    "\n",
    "We score PPG by looking at the heartrate inferred from PPG, and computing the euclidean distance to the average heartrate computed across the 3 ECG channels. We then score them on their distance from ECG_HR based on the mean and stdev of the distances.\n",
    "\n",
    "If d < mean - stdev (between 0 and 1 stdev less tham mean), it is excellent\n",
    "if (mean-stdev) <= d <= (mean+stdev), it is good\n",
    "if d > (mean~stdev), it is poor\n",
    "\n",
    "```\n",
    "Let m be the mean distance\n",
    "Let s be the stdev of the distances\n",
    "\n",
    "  |----- EXCELLENT ----|--- GOOD ----|----- POOR -------|\n",
    "  |--------------------|------+------|------------------|\n",
    "min(d)               (m-s)    m    (m+s)              max(d)"
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-26T14:51:58.911587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hr_distances = []\n",
    "\n",
    "for p in range(CUADS_NUM_PARTICIPANTS):\n",
    "    folder = f\"{dataset_root}/CUADS_{(p+1):03}\"\n",
    "    if not os.path.exists(folder):\n",
    "        continue\n",
    "\n",
    "    # Load this participant's responses...\n",
    "    responses = np.loadtxt(f\"{folder}/responses.csv\", delimiter=',', dtype=str, skiprows=1)\n",
    "\n",
    "    for response in responses:\n",
    "        movie_name = response[0]\n",
    "        segmented_data_filepath = f'{folder}/segmented/{movie_name}_sessiondata.csv'\n",
    "        if not os.path.exists(segmented_data_filepath):\n",
    "            print(f\"No segmented datafile found: {segmented_data_filepath}\")\n",
    "            continue\n",
    "\n",
    "        segmented_data = np.loadtxt(segmented_data_filepath, delimiter=',', dtype=str, skiprows=1)\n",
    "\n",
    "        ## ECG LA-RA HR = Column 20\n",
    "        ## ECG LL-LA HR = Column 21\n",
    "        ## ECG LL-RA HR = Column 22\n",
    "        ## PPG HR       = Column 48\n",
    "\n",
    "        ecg_avg_hr = np.array(segmented_data[:,19:21],dtype=float).mean(axis=1)\n",
    "        ppg_hr = np.array(segmented_data[:,47],dtype=float)\n",
    "        hr_distances.append(np.sqrt(np.sum(np.square(ecg_avg_hr-ppg_hr))))\n",
    "\n",
    "print(\"Heart Rate Stats:\")\n",
    "hr_distances = np.array(hr_distances)\n",
    "mu = np.mean(hr_distances)\n",
    "sigma = np.std(hr_distances)\n",
    "print(f\"Min: {np.min(hr_distances)})\")\n",
    "print(f\"Max: {np.max(hr_distances)}\")\n",
    "print(f\"Stdev: {sigma}\")\n",
    "print(f\"Mean: {mu}\")\n",
    "print(\"\\nScores:\")\n",
    "print(f\"Poor: {len([ d for d in hr_distances if d > (mu+sigma)])}\")\n",
    "print(f\"Good: {len([ d for d in hr_distances if (mu-sigma) <= d <= (mu+sigma)])}\")\n",
    "print(f\"Excellent: {len([ d for d in hr_distances if d < (mu-sigma)])}\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# GSR Scoring\n",
    "\n",
    "Implemented across the next two cells\n",
    "\n",
    "We score GSR based on RMSE of the Skin Conductance signals. We calculate a reference signal for each participant by averaging skin conductance for all samples from that participant. We then compute the distance from baseline for each signal and rate them as `poor`, `good` or `excellent` based on distance from the mean."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gsr_signals_by_participant = {}\n",
    "\n",
    "# Load each GSR-SC signal by participant...\n",
    "for p in range(CUADS_NUM_PARTICIPANTS):\n",
    "    folder = f\"{dataset_root}/CUADS_{(p+1):03}\"\n",
    "    if not os.path.exists(folder):\n",
    "        continue\n",
    "\n",
    "    # Load this participant's responses...\n",
    "    responses = np.loadtxt(f\"{folder}/responses.csv\", delimiter=',', dtype=str, skiprows=1)\n",
    "\n",
    "    # Create a list to hold the GSR signals for this participant...\n",
    "    gsr_signals_by_participant[p] = []\n",
    "\n",
    "    for c, response in enumerate(responses):\n",
    "        movie_name = response[0]\n",
    "        segmented_data_filepath = f'{folder}/segmented/{movie_name}_sessiondata.csv'\n",
    "        if not os.path.exists(segmented_data_filepath):\n",
    "            print(f\"No segmented datafile found: {segmented_data_filepath}\")\n",
    "            continue\n",
    "\n",
    "        segmented_data = np.loadtxt(segmented_data_filepath, delimiter=',', dtype=str, skiprows=1)\n",
    "\n",
    "        ## GSR Skin Conductance = Column 37\n",
    "        skin_conductance = np.array(segmented_data[:,36],dtype=float)\n",
    "        gsr_signals_by_participant[p].append(skin_conductance)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rmse_results = {}\n",
    "\n",
    "for participant, gsr_signals in gsr_signals_by_participant.items():\n",
    "    # Determine the maximum length of segmented data files for this participant\n",
    "    max_length = max(len(gsr_signal) for gsr_signal in gsr_signals)\n",
    "\n",
    "    # Pad all segmented data files to the maximum length with zeros\n",
    "    padded_datasets = [np.pad(gsr_signal, (0, max_length - len(gsr_signal)), mode='constant') for gsr_signal in gsr_signals]\n",
    "\n",
    "    # Compute the reference signal (mean across padded datasets)\n",
    "    reference_signal = np.mean(padded_datasets, axis=0)\n",
    "\n",
    "    # Compute normalized RMSE for each segmented data file\n",
    "    rmses = []\n",
    "    for gsr_signal in gsr_signals:\n",
    "        T_i = len(gsr_signal)  # Actual length of the dataset\n",
    "        padded_dataset = np.pad(gsr_signal, (0, max_length - T_i), mode='constant')  # Pad to match reference length\n",
    "        rmse = np.sqrt(np.sum((padded_dataset[:T_i] - reference_signal[:T_i]) ** 2) / T_i)  # Normalize by T_i\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    # Compute thresholds for classification\n",
    "    mu = np.mean(rmses)  # Mean of RMSE values\n",
    "    sigma = np.std(rmses)  # Standard deviation of RMSE values\n",
    "\n",
    "    classifications = []\n",
    "    for rmse in rmses:\n",
    "        if rmse < mu - sigma:\n",
    "            classifications.append(\"Excellent\")\n",
    "        elif mu - sigma <= rmse <= mu + sigma:\n",
    "            classifications.append(\"Good\")\n",
    "        else:\n",
    "            classifications.append(\"Poor\")\n",
    "\n",
    "    # Store results and classifications for the participant\n",
    "    rmse_results[participant] = {\n",
    "        \"RMSE Values\": rmses,\n",
    "        \"Classifications\": classifications\n",
    "    }\n",
    "\n",
    "# Convert results into a DataFrame for easier analysis\n",
    "participant_results = []\n",
    "for participant, results in rmse_results.items():\n",
    "    for i, (rmse, classification) in enumerate(zip(results[\"RMSE Values\"], results[\"Classifications\"])):\n",
    "        participant_results.append({\n",
    "            \"Participant\": participant,\n",
    "            \"Segmented File ID\": i + 1,\n",
    "            \"RMSE\": rmse,\n",
    "            \"Classification\": classification\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(participant_results)\n",
    "\n",
    "# Display the results in tabular format\n",
    "# Count the total number of each classification\n",
    "classification_counts = results_df[\"Classification\"].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(\"Total Classifications:\")\n",
    "print(classification_counts)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Participant Response Scoring"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "participant_responses_quadrant = np.zeros(shape=(CUADS_NUM_PARTICIPANTS, CUADS_NUM_MOVIECLIPS), dtype=int)\n",
    "expected_responses_quadrant = np.zeros(shape=(CUADS_NUM_MOVIECLIPS), dtype=int)\n",
    "\n",
    "expected_label_map = {\n",
    "    np.str_('video_55'): 2,\n",
    "    np.str_('video_79'): 1,\n",
    "    np.str_('video_111'): 3,\n",
    "    np.str_('video_73'): 2,\n",
    "    np.str_('video_52'): 4,\n",
    "    np.str_('video_146'): 3,\n",
    "    np.str_('video_funny_f'): 1,\n",
    "    np.str_('video_80'): 1,\n",
    "    np.str_('video_cats_f'): 1,\n",
    "    np.str_('video_138'): 3,\n",
    "    np.str_('video_69'): 2,\n",
    "    np.str_('video_dallas_f'): 0,\n",
    "    np.str_('video_detroit_f'): 0,\n",
    "    np.str_('video_53'): 4,\n",
    "    np.str_('video_58'): 4,\n",
    "    np.str_('video_30'): 2,\n",
    "    np.str_('video_earworm_f'): 2,\n",
    "    np.str_('video_newyork_f'): 0,\n",
    "    np.str_('video_90'): 1,\n",
    "    np.str_('video_107'): 2\n",
    "}\n",
    "\n",
    "# Since participants viewed movies in a random order we need\n",
    "# to track what sequence we encounter the movies in during processing,\n",
    "# so that we have consistent indexing later.\n",
    "movie_idx_map={}\n",
    "movie_idx = 0\n",
    "\n",
    "def to_quadrant(a, v):\n",
    "    q = -1\n",
    "    if a >= 5:\n",
    "        if v >= 5:\n",
    "            q = 1\n",
    "        else:\n",
    "            q = 2\n",
    "    else:\n",
    "        if v < 5:\n",
    "            q = 3\n",
    "        else:\n",
    "            q = 4\n",
    "    return q\n",
    "\n",
    "for p in range(CUADS_NUM_PARTICIPANTS):\n",
    "    folder = f\"{dataset_root}/CUADS_{(p+1):03}\"\n",
    "    if not os.path.exists(folder):\n",
    "        continue\n",
    "\n",
    "    responses = np.loadtxt(f\"{folder}/responses.csv\", delimiter=',', dtype=str, skiprows=1)\n",
    "\n",
    "    for c, response in enumerate(responses):\n",
    "        movie_name = response[0]\n",
    "\n",
    "        # If we haven't indexed this movie yet, add it to the movie_idx_map\n",
    "        # and also index its expected response accordingly\n",
    "        if movie_name not in movie_idx_map:\n",
    "            movie_idx_map[movie_name]=movie_idx\n",
    "            expected_responses_quadrant[ movie_idx] = expected_label_map[movie_name]\n",
    "            movie_idx+=1\n",
    "\n",
    "        v=float(response[1])\n",
    "        a=float(response[2])\n",
    "\n",
    "        participant_responses_quadrant[p][movie_idx_map[movie_name]] = to_quadrant(a, v)\n",
    "\n",
    "\n",
    "def convert_quadrant_to_arousal(value):\n",
    "    if value == 0:\n",
    "        return 0\n",
    "    elif value in [1, 2]:\n",
    "        return 1\n",
    "    elif value in [3, 4]:\n",
    "        return -1\n",
    "\n",
    "def convert_quadrant_to_valence(value):\n",
    "    if value == 0:\n",
    "        return 0\n",
    "    elif value in [1, 4]:\n",
    "        return 1\n",
    "    elif value in [2, 3]:\n",
    "        return -1\n",
    "\n",
    "\n",
    "# Apply the conversion\n",
    "participant_responses_arousal = np.vectorize(convert_quadrant_to_arousal)(participant_responses_quadrant)\n",
    "participant_responses_valence = np.vectorize(convert_quadrant_to_valence)(participant_responses_quadrant)\n",
    "expected_responses_arousal = np.vectorize(convert_quadrant_to_arousal)(expected_responses_quadrant)\n",
    "expected_responses_valence = np.vectorize(convert_quadrant_to_valence)(expected_responses_quadrant)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_kappa_scores( kappa_input, title ):\n",
    "    kappa_scores = []\n",
    "    for i in range(kappa_input.shape[0]):\n",
    "        clip_input = kappa_input[i:i + 1, :]  # Extract one row for the current clip\n",
    "        if np.sum(clip_input) > 0:  # Ensure there is at least one valid response\n",
    "            kappa_score = fleiss_kappa(clip_input, method='randolph')\n",
    "            kappa_scores.append(kappa_score)\n",
    "        else:\n",
    "            kappa_scores.append(None)  # Handle empty clips gracefully\n",
    "\n",
    "    ## Create bar chart for Fleiss' Kappa scores\n",
    "    clip_indices = list(range(1, len(kappa_scores) + 1))\n",
    "    data = [score if score is not None else 0 for score in kappa_scores]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(clip_indices, data, color='skyblue')\n",
    "    plt.xticks(clip_indices)\n",
    "    plt.xlabel(\"Movie Clip\")\n",
    "    plt.ylabel(\"Randolph's Kappa Score\")\n",
    "    plt.title(title)\n",
    "    plt.ylim(np.min(kappa_scores)*-1.1, 1.1*np.max(np.abs(kappa_scores)))  # Fleiss' Kappa ranges from -1 to 1\n",
    "    plt.axhline(0, color='gray', linestyle='--', linewidth=0.8)  # Reference line for 0 agreement\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def prepare_kappa_input( responses ):\n",
    "    (result, labels) = aggregate_raters(responses.transpose())\n",
    "\n",
    "    zeroidx = np.where(labels == 0)[0]\n",
    "    result = np.delete(result, zeroidx, axis=1)\n",
    "\n",
    "    return result\n",
    "\n",
    "def pad_kappa_inputs_to_n_raters( kappa_input ):\n",
    "    n_raters = int(kappa_input.sum(axis=1).max())\n",
    "    if not np.all(kappa_input.sum(axis=1) == n_raters):\n",
    "        # Normalize all clips to have the same number of ratings\n",
    "        for i in range(kappa_input.shape[0]):\n",
    "            total_responses = int(kappa_input[i].sum())\n",
    "\n",
    "            if total_responses < n_raters:\n",
    "                # Add missing responses proportionally based on existing counts\n",
    "                proportions = kappa_input[i] / total_responses\n",
    "                missing_responses = n_raters - total_responses\n",
    "                additional_responses = np.random.multinomial(missing_responses, proportions)\n",
    "\n",
    "                kappa_input[i] += additional_responses\n",
    "\n",
    "    return kappa_input\n",
    "\n",
    "def process_kappa( participant_responses, response_type ):\n",
    "    # Prepare kappa input based on arousal results\n",
    "    kappa_input = prepare_kappa_input(participant_responses)\n",
    "    kappa_input = pad_kappa_inputs_to_n_raters(kappa_input)\n",
    "    plot_kappa_scores(kappa_input, f\"Randolph's Kappa Agreement Scores Across Movie Clips - {response_type}\")\n",
    "\n",
    "    # Calculate Fleiss' Kappa using only non-neutral movies\n",
    "    kappa_score = fleiss_kappa(kappa_input, method='randolph')\n",
    "    print(\"Randolph's Kappa Score:\", kappa_score)\n",
    "\n",
    "    # Identify indices of non-neutral movies\n",
    "    # Filter the fleiss_input matrix to exclude neutral movies\n",
    "    non_neutral_movie_indices = [i for i, label in enumerate(expected_responses_quadrant) if label != 0]\n",
    "    filtered_kappa_input = kappa_input[non_neutral_movie_indices]\n",
    "    plot_kappa_scores(filtered_kappa_input, f\"Randolph's Kappa Agreement Scores Across Non-Neutral Movie Clips - {response_type}\")\n",
    "\n",
    "    # Calculate Randolph's Kappa using only non-neutral movies\n",
    "    filtered_kappa_score = fleiss_kappa(filtered_kappa_input, method='randolph')\n",
    "    print(\"Randolph's Kappa Score (excluding neutral movies):\", filtered_kappa_score)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "process_kappa( participant_responses_arousal, \"Arousal\")\n",
    "process_kappa( participant_responses_valence, \"Valence\")\n",
    "process_kappa(participant_responses_quadrant, \"Quadrant\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def stats(y_true, y_pred, classes):\n",
    "    # Compute Accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Compute Precision and Recall for Each Class\n",
    "    precision = precision_score(y_true, y_pred, average=None)  # Per-class precision\n",
    "    recall = recall_score(y_true, y_pred, average=None)        # Per-class recall\n",
    "\n",
    "    # Macro and Weighted Averages\n",
    "    macro_precision = precision_score(y_true, y_pred, average='macro')\n",
    "    macro_recall = recall_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    weighted_precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    weighted_recall = recall_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    # Print Results\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(\"Per-Class Precision:\", precision)\n",
    "    print(\"Per-Class Recall:\", recall)\n",
    "    print(f\"Macro Precision: {macro_precision:.2f}\")\n",
    "    print(f\"Macro Recall: {macro_recall:.2f}\")\n",
    "    print(f\"Weighted Precision: {weighted_precision:.2f}\")\n",
    "    print(f\"Weighted Recall: {weighted_recall:.2f}\")\n",
    "\n",
    "    # Optional: Full Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=classes))\n",
    "\n",
    "\n",
    "def make_matrix(cm_responses, cm_labels, cm_classes, cm_xlabel, cm_ylabel, fname):\n",
    "    non_neutral_movie_indices = [i for i, label in enumerate(cm_labels) if label != 0]\n",
    "    confusion_responses = cm_responses[:, non_neutral_movie_indices]\n",
    "\n",
    "    expected_labels = cm_labels[non_neutral_movie_indices]\n",
    "\n",
    "    valid_responses = confusion_responses.flatten() != 0\n",
    "    y_true = np.tile(expected_labels, confusion_responses.shape[0])[valid_responses]\n",
    "    y_pred = confusion_responses.flatten()[valid_responses]\n",
    "    stats(y_true, y_pred, cm_classes)\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        normalize=\"pred\"\n",
    "    )\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='.2f', cmap=\"Greys\", xticklabels=cm_classes, yticklabels=cm_classes, annot_kws={\"size\": 18})\n",
    "    plt.xlabel(cm_xlabel, fontsize=12)\n",
    "    plt.ylabel(cm_ylabel, fontsize=12)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.savefig(fname, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "cm_responses = participant_responses_quadrant\n",
    "cm_labels = expected_responses_quadrant\n",
    "cm_classes = [\"I\", \"II\", \"III\", \"IV\" ]\n",
    "cm_xlabel = \"Expected Rating (Quadrant)\"\n",
    "cm_ylabel = \"Participant Rating (Quadrant)\"\n",
    "make_matrix(\n",
    "    cm_responses,\n",
    "    cm_labels,\n",
    "    cm_classes,\n",
    "    cm_xlabel,\n",
    "    cm_ylabel,\n",
    "    f\"{dataset_ouput}/quadrant_matrix.png\"\n",
    ")\n",
    "\n",
    "cm_responses = participant_responses_arousal\n",
    "cm_labels = expected_responses_arousal\n",
    "cm_classes = [\"Low\", \"High\" ]\n",
    "cm_xlabel = \"Expected Rating (Arousal)\"\n",
    "cm_ylabel = \"Participant Rating (Arousal)\"\n",
    "make_matrix(\n",
    "    cm_responses,\n",
    "    cm_labels,\n",
    "    cm_classes,\n",
    "    cm_xlabel,\n",
    "    cm_ylabel,\n",
    "    \"{dataset_ouput}/arousal_matrix.png\"\n",
    ")\n",
    "\n",
    "cm_responses = participant_responses_valence\n",
    "cm_labels = expected_responses_valence\n",
    "cm_classes = [\"Negative\", \"Positive\" ]\n",
    "cm_xlabel = \"Expected Rating (Valence)\"\n",
    "cm_ylabel = \"Participant Rating (Valence)\"\n",
    "make_matrix(\n",
    "    cm_responses,\n",
    "    cm_labels,\n",
    "    cm_classes,\n",
    "    cm_xlabel,\n",
    "    cm_ylabel,\n",
    "    \"{dataset_ouput}/valence_matrix.png\"\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
